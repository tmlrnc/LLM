{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b099c82a-af94-4bca-9b3c-ca2b526f165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from PyPDF2 import PdfReader\n",
    "import openai\n",
    "import pinecone\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "GenAi assistant for documenting a business process. \n",
    "\n",
    "The documentation serves multiple purposes, including ensuring transparency, facilitating communication, and providing a reference for auditing, improvement, or compliance purposes. \n",
    "\n",
    "Here's how an expert auditor might document a business process:\n",
    "\n",
    "Describe Each Step:\n",
    "For each step in the process, provide a detailed description. Include information such as:\n",
    "\n",
    "Activity Name: Clearly label each step.\n",
    "Inputs: Identify the inputs required for each activity.\n",
    "Outputs: Specify the expected outputs produced by each activity.\n",
    "\n",
    "Create a Process Flowchart:\n",
    "Develop a visual representation of the process flowchart. Use dash symbols to represent activities, decision points, inputs, outputs, and flow direction. The flowchart provides a high-level overview of the process and helps in understanding the sequence of steps.\n",
    "\n",
    "\n",
    "Here is a POC of how a GenAI applicationcan in assistant  documenting a business process\n",
    "\n",
    "Text Extraction from PDF:\n",
    "There's a function (extract_text_from_pdf) that takes a PDF file path as input and extracts text from each page, cleaning and concatenating it into a single string.\n",
    "\n",
    "Text Summarization:\n",
    "Another function (summarize_process_data) uses the OpenAI API to generate a human-readable summary of the given text using the \"davinci\" engine.\n",
    "\n",
    "Saving Summaries to Files:\n",
    "The script has a function (save_summary_to_file) that saves the generated summary to a text file.\n",
    "\n",
    "Processing PDFs and Summarizing Data:\n",
    "A function (load_pinecone_with_process_summary) loads a PDF file, extracts text, generates a summary, and saves the summary to multiple files.\n",
    "\n",
    "Text Chunking and Embedding:\n",
    "There are functions (split_text_into_chunks and create_embedding) that break down text into chunks and create embeddings using the OpenAI Embedding API.\n",
    "\n",
    "Loading Data into Pinecone:\n",
    "The script includes a function (load_pinecone_with_process_data) that loads text data into Pinecone by converting chunks into embeddings and indexing them.\n",
    "\n",
    "Querying Pinecone for Similar Documents:\n",
    "There's a function (rag_query_pinecone) that queries Pinecone for similar documents based on a given text input.\n",
    "\n",
    "Processing Queries Using ChatCompletion:\n",
    "Functions (process_query_with_docs and process_query) use ChatCompletion from the OpenAI API to process queries and generate responses.\n",
    "\n",
    "Develop a visual representation of the process flowchart. \n",
    "Use dash symbols to represent activities, decision points, inputs, outputs, and flow direction. The flowchart provides a high-level overview of the process and helps in understanding the sequence of steps.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "PIINECONE_INDEX = \"your_index_name\"  # Replace with your actual Pinecone index name\n",
    "PINECONE_API_KEY = \"your_pinecone_api_key\"  # Replace with your actual Pinecone API key\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    meta = reader.metadata\n",
    "    print(meta)\n",
    "    num_pages = len(reader.pages)\n",
    "    full_text = \"\"\n",
    "    \n",
    "    for next_page_num in range(num_pages):\n",
    "        page_read = reader.pages[next_page_num]\n",
    "        page_text = page_read.extract_text()\n",
    "        page_text_ascii = page_text.encode(\"ascii\", \"ignore\")\n",
    "        page_text_clean = page_text_ascii.decode()\n",
    "        full_text += page_text_clean\n",
    "    \n",
    "    return full_text.strip()\n",
    "\n",
    "def summarize_process_data(process_data):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"davinci\",\n",
    "        prompt=f'Summarize the key process topics from given text in human readable paragraphs: {process_data}',\n",
    "        max_tokens=500\n",
    "    )\n",
    "    summary = response.choices[0].text.strip()\n",
    "    return summary\n",
    "\n",
    "def save_summary_to_file(summary, state, page_num):\n",
    "    file_txt = f\"apps/chats/data/raw_data/{state}_{page_num}.txt\"\n",
    "    with open(file_txt, 'w') as f:\n",
    "        f.write(summary)\n",
    "\n",
    "def load_pinecone_with_process_summary(process_summary_doc_file_name, state):\n",
    "    file_pdf = process_summary_doc_file_name\n",
    "    full_text = extract_text_from_pdf(file_pdf)\n",
    "    process_data_summary = summarize_process_data(full_text)\n",
    "    \n",
    "    for next_page_num in range(10):  # Adjust the number of pages as needed\n",
    "        save_summary_to_file(process_data_summary, state, next_page_num)\n",
    "\n",
    "def split_text_into_chunks(text):\n",
    "    words = text.split()\n",
    "    text_chunks = []\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        chunk = ' '.join(words[i:i+chunk_size])\n",
    "        text_chunks.append(chunk)\n",
    "    return text_chunks\n",
    "\n",
    "def create_embedding(chunk):\n",
    "    response = openai.Embedding.create(\n",
    "            input=chunk,\n",
    "            model=\"text-embedding-ada-002\"\n",
    "        )\n",
    "    return response[\"data\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "def load_pinecone_with_process_data(process_name, model=\"text-embedding-ada-002\", index_name=PIINECONE_INDEX):\n",
    "    file_pdf = f\"./process_history_data/{process_name}.pdf\"\n",
    "    full_text = extract_text_from_pdf(file_pdf)\n",
    "    \n",
    "    process_data = full_text.strip()\n",
    "\n",
    "    index_name = PIINECONE_INDEX\n",
    "    text_chunks = split_text_into_chunks(process_data)\n",
    "    \n",
    "    pinecone.init(api_key=PINECONE_API_KEY, environment=\"us-east1-gcp\")\n",
    "    pinecone_index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "    for chunk in text_chunks:\n",
    "        id = uuid.uuid4().hex\n",
    "        embedding = create_embedding(chunk)\n",
    "        embedding_sample_doc = [\n",
    "            {\n",
    "                \"id\": id,\n",
    "                \"values\": embedding,\n",
    "                \"metadata\": {\n",
    "                    \"id\": id,\n",
    "                    \"text\": chunk\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        pinecone_index.upsert(embedding_sample_doc)\n",
    "\n",
    "def rag_query_pinecone(text, model=\"text-embedding-ada-002\", index_name=PIINECONE_INDEX, top_k=2):\n",
    "    pinecone.init(api_key=PINECONE_API_KEY, environment=\"us-east1-gcp\")\n",
    "    index = pinecone.Index(index_name)\n",
    "    query_vector = get_embedding(text, model)\n",
    "    result = index.query(queries=[query_vector], top_k=top_k, includeMetadata=True)\n",
    "    \n",
    "    output_texts = ''\n",
    "    threshold = 0.8\n",
    "\n",
    "    results = result['results']\n",
    "    for result in results:\n",
    "        matches = result['matches']\n",
    "        for match in matches:\n",
    "            if match['score'] < threshold:\n",
    "                continue\n",
    "            metadata = match['metadata']\n",
    "            text = metadata['text']\n",
    "            source = metadata['source']\n",
    "            output_texts += f\"source: {source}\\ntext: {text}\\n\\n\"\n",
    "    \n",
    "    context = output_texts\n",
    "    return context\n",
    "\n",
    "def process_query_with_docs(process_summary, openai_api_key):\n",
    "\n",
    "    # Generate step headings with dash boxes using ChatCompletion\n",
    "    step_headings_prompt = f'Generate step headings with dash boxes for the given process steps: {process_summary}'\n",
    "    step_headings_response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': step_headings_prompt},\n",
    "            {'role': 'user', 'content': ''}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    step_headings = step_headings_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    # Use the generated step headings in the process prompt\n",
    "    process_prompt += f\"\\n\\nGenerated Step Headings:\\n\\n{step_headings}\"\n",
    "\n",
    "    # Make the final ChatCompletion call\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': process_prompt},\n",
    "            {'role': 'user', 'content': text_message}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    prompt_response = response[\"choices\"][0][\"message\"]['content']\n",
    "    print(prompt_response)\n",
    "\n",
    "def process_query(mysteps, openai_api_key):\n",
    "    \n",
    "    rag_search_pinecone_response = rag_query_pinecone(mysteps)\n",
    "    print('rag_search_pinecone_response ..............................')\n",
    "    print(rag_search_pinecone_response)\n",
    "    \n",
    "    process_prompt = f'as an expert auditor describe the details of the steps needed to successfully implement the process in the following step by step process: {mysteps} and use the following process expert data to enhance each current step: {rag_search_pinecone_response} '\n",
    "    \n",
    "    response = openai.ChatCompletion.create(model=\"gpt-4\", messages=[\n",
    "        {'role': 'system', 'content': process_prompt},\n",
    "        {'role': 'user', 'content': text_message}\n",
    "    ], temperature=0)\n",
    "    \n",
    "    prompt_response = response[\"choices\"][0][\"message\"]['content']\n",
    "\n",
    "def main():\n",
    "\n",
    "\n",
    "    ############################################################################################################################################\n",
    "    #    Bank Deposit Operations Process\n",
    "    ############################################################################################################################################\n",
    "    \n",
    "    mysteps = {\n",
    "        \"process_steps\": [\n",
    "        \"Step 1: Customer Initiation of Bank Deposit Request of $AMOUNT\",\n",
    "        \"Step 2: Document Verification\",\n",
    "        \"Step 3: Amount Verification\",\n",
    "        \"Step 4: Fee Assessment\",\n",
    "        \"Step 5: Fraud Detection\",\n",
    "        \"Step 6: Customer Identification\",\n",
    "        \"Step 7: Transaction Recording\",\n",
    "        \"Step 8: Endorsement Verification\",\n",
    "        \"Step 9: Cash Handling Procedures\",\n",
    "        \"Step 10: Error Detection\",\n",
    "        \"Step 11: Record Retention\",\n",
    "        \"Step 12: Reporting\",\n",
    "        \"Step 13: Audit Trail Documentation\",\n",
    "        \"Step 14: Compliance Check\",\n",
    "        \"Step 15: Continuous Monitoring\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    bank_process_summary = process_query(mysteps, PINECONE_API_KEY)\n",
    "    print(process_summary)\n",
    "    bank_process_step_by_step_documenation = process_query(bank_process_summary, PINECONE_API_KEY)\n",
    "    print(process_step_by_step_documenation)\n",
    "\n",
    "    ############################################################################################################################################\n",
    "    #    Agile Software Development Process\n",
    "    ############################################################################################################################################\n",
    "    \n",
    "    mysteps_for_dev = {\n",
    "        \"process_steps\": [\n",
    "        \"Step 1: Continuous integration\",\n",
    "        \"Step 2: Automated unit testing\",\n",
    "        \"Step 3: Pair programming,\n",
    "        \"Step 4: Test-driven development\",\n",
    "        \"Step 5: Design patterns\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    devevlopment_process_summary = process_query(mysteps_for_dev, PINECONE_API_KEY)\n",
    "    print(process_summary)\n",
    "    developemnt_process_step_by_step_documenation = process_query(devevlopment_process_summary, PINECONE_API_KEY)\n",
    "    print(developemnt_process_step_by_step_documenation)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
